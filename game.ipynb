{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from pulp import LpMinimize, LpMaximize, LpProblem, LpStatus, lpSum, LpVariable, value, GLPK\n",
    "\n",
    "OBJ_EPSILON = 1e-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Game(object):\n",
    "    def __init__(self, config, env, random_seed=1000):\n",
    "        self.random_state = np.random.RandomState(seed=random_seed)\n",
    " \n",
    "        self.data_dir = env.data_dir\n",
    "        self.DG = env.topology.DG\n",
    "        self.traffic_file = env.traffic_file\n",
    "        self.traffic_matrices = env.traffic_matrices\n",
    "        self.traffic_matrices_dims = self.traffic_matrices.shape\n",
    "        self.tm_cnt = env.tm_cnt\n",
    "        self.num_pairs = env.num_pairs\n",
    "        self.pair_idx_to_sd = env.pair_idx_to_sd\n",
    "        self.pair_sd_to_idx = env.pair_sd_to_idx\n",
    "        self.num_nodes = env.num_nodes\n",
    "        self.num_links = env.num_links\n",
    "        self.link_idx_to_sd = env.link_idx_to_sd\n",
    "        self.link_sd_to_idx = env.link_sd_to_idx\n",
    "        self.link_capacities = env.link_capacities\n",
    "        self.link_weights = env.link_weights\n",
    "        self.shortest_paths_node = env.shortest_paths_node              # paths with node info\n",
    "        self.shortest_paths_link = env.shortest_paths_link              # paths with link info\n",
    "\n",
    "        self.get_ecmp_next_hops()\n",
    "        \n",
    "        self.model_type = config.model_type\n",
    "        \n",
    "        #for LP\n",
    "        self.lp_pairs = [p for p in range(self.num_pairs)]\n",
    "        self.lp_nodes = [n for n in range(self.num_nodes)]\n",
    "        self.links = [e for e in range(self.num_links)]\n",
    "        self.lp_links = [e for e in self.link_sd_to_idx]\n",
    "        self.pair_links = [(pr, e[0], e[1]) for pr in self.lp_pairs for e in self.lp_links]\n",
    "\n",
    "        self.load_multiplier = {}\n",
    "        \n",
    "    def generate_inputs(self, normalization=True):\n",
    "        self.normalized_traffic_matrices = np.zeros((self.valid_tm_cnt, self.traffic_matrices_dims[1], self.traffic_matrices_dims[2], self.tm_history), dtype=np.float32)   #tm state  [Valid_tms, Node, Node, History]\n",
    "        idx_offset = self.tm_history - 1\n",
    "        for tm_idx in self.tm_indexes:\n",
    "            for h in range(self.tm_history):\n",
    "                if normalization:\n",
    "                    tm_max_element = np.max(self.traffic_matrices[tm_idx-h])\n",
    "                    self.normalized_traffic_matrices[tm_idx-idx_offset,:,:,h] = self.traffic_matrices[tm_idx-h] / tm_max_element        #[Valid_tms, Node, Node, History]\n",
    "                else:\n",
    "                    self.normalized_traffic_matrices[tm_idx-idx_offset,:,:,h] = self.traffic_matrices[tm_idx-h]                         #[Valid_tms, Node, Node, History]\n",
    "\n",
    "    def get_topK_flows(self, tm_idx, pairs):\n",
    "        tm = self.traffic_matrices[tm_idx]\n",
    "        f = {}\n",
    "        for p in pairs:\n",
    "            s, d = self.pair_idx_to_sd[p]\n",
    "            f[p] = tm[s][d]\n",
    "\n",
    "        sorted_f = sorted(f.items(), key = lambda kv: (kv[1], kv[0]), reverse=True)\n",
    "\n",
    "        cf = []\n",
    "        for i in range(self.max_moves):\n",
    "            cf.append(sorted_f[i][0])\n",
    "\n",
    "        return cf\n",
    "       \n",
    "    def get_ecmp_next_hops(self):\n",
    "        self.ecmp_next_hops = {}\n",
    "        for src in range(self.num_nodes):\n",
    "            for dst in range(self.num_nodes):\n",
    "                if src == dst:\n",
    "                    continue\n",
    "                self.ecmp_next_hops[src, dst] = []\n",
    "                for p in self.shortest_paths_node[self.pair_sd_to_idx[(src, dst)]]:\n",
    "                    if p[1] not in self.ecmp_next_hops[src, dst]:\n",
    "                        self.ecmp_next_hops[src, dst].append(p[1])\n",
    "\n",
    "    def ecmp_next_hop_distribution(self, link_loads, demand, src, dst):\n",
    "        if src == dst:\n",
    "            return\n",
    "\n",
    "        ecmp_next_hops = self.ecmp_next_hops[src, dst]\n",
    "\n",
    "        next_hops_cnt = len(ecmp_next_hops)\n",
    "        #if next_hops_cnt > 1:\n",
    "            #print(self.shortest_paths_node[self.pair_sd_to_idx[(src, dst)]])\n",
    "\n",
    "        ecmp_demand = demand / next_hops_cnt \n",
    "        for np in ecmp_next_hops:\n",
    "            link_loads[self.link_sd_to_idx[(src, np)]] += ecmp_demand\n",
    "            self.ecmp_next_hop_distribution(link_loads, ecmp_demand, np, dst)\n",
    "\n",
    "    def ecmp_traffic_distribution(self, tm_idx):\n",
    "        link_loads = np.zeros((self.num_links))\n",
    "        tm = self.traffic_matrices[tm_idx]\n",
    "        for pair_idx in range(self.num_pairs):\n",
    "            s, d = self.pair_idx_to_sd[pair_idx]\n",
    "            demand = tm[s][d]\n",
    "            if demand != 0:\n",
    "                self.ecmp_next_hop_distribution(link_loads, demand, s, d)\n",
    "\n",
    "        return link_loads\n",
    "\n",
    "    def get_critical_topK_flows(self, tm_idx, critical_links=5):\n",
    "        link_loads = self.ecmp_traffic_distribution(tm_idx)\n",
    "        critical_link_indexes = np.argsort(-(link_loads / self.link_capacities))[:critical_links]\n",
    "        \n",
    "        cf_potential = []\n",
    "        for pair_idx in range(self.num_pairs):\n",
    "            for path in self.shortest_paths_link[pair_idx]:\n",
    "                if len(set(path).intersection(critical_link_indexes)) > 0:\n",
    "                    cf_potential.append(pair_idx)\n",
    "                    break\n",
    "\n",
    "        #print(cf_potential)\n",
    "        assert len(cf_potential) >= self.max_moves, \\\n",
    "                (\"cf_potential(%d) < max_move(%d), please increse critical_links(%d)\"%(cf_potential, self.max_moves, critical_links))\n",
    "\n",
    "        return self.get_topK_flows(tm_idx, cf_potential)\n",
    "        \n",
    "    def eval_ecmp_traffic_distribution(self, tm_idx, eval_delay=False):\n",
    "        eval_link_loads = self.ecmp_traffic_distribution(tm_idx)\n",
    "        eval_max_utilization = np.max(eval_link_loads / self.link_capacities)\n",
    "        self.load_multiplier[tm_idx] = 0.9 / eval_max_utilization\n",
    "        delay = 0\n",
    "        if eval_delay:\n",
    "            eval_link_loads *= self.load_multiplier[tm_idx]\n",
    "            delay = sum(eval_link_loads / (self.link_capacities - eval_link_loads))\n",
    "\n",
    "        return eval_max_utilization, delay\n",
    "   \n",
    "    def optimal_routing_mlu(self, tm_idx):\n",
    "        tm = self.traffic_matrices[tm_idx]\n",
    "        demands = {}\n",
    "        for i in range(self.num_pairs):\n",
    "            s, d = self.pair_idx_to_sd[i]\n",
    "            demands[i] = tm[s][d]\n",
    "\n",
    "        model = LpProblem(name=\"routing\")\n",
    "       \n",
    "        ratio = LpVariable.dicts(name=\"ratio\", indexs=self.pair_links, lowBound=0, upBound=1)\n",
    "\n",
    "        link_load = LpVariable.dicts(name=\"link_load\", indexs=self.links)\n",
    "\n",
    "        r = LpVariable(name=\"congestion_ratio\")\n",
    "\n",
    "        for pr in self.lp_pairs:\n",
    "            model += (lpSum([ratio[pr, e[0], e[1]] for e in self.lp_links if e[1] == self.pair_idx_to_sd[pr][0]]) - lpSum([ratio[pr, e[0], e[1]] for e in self.lp_links if e[0] == self.pair_idx_to_sd[pr][0]]) == -1, \"flow_conservation_constr1_%d\"%pr)\n",
    "\n",
    "        for pr in self.lp_pairs:\n",
    "            model += (lpSum([ratio[pr, e[0], e[1]] for e in self.lp_links if e[1] == self.pair_idx_to_sd[pr][1]]) - lpSum([ratio[pr, e[0], e[1]] for e in self.lp_links if e[0] == self.pair_idx_to_sd[pr][1]]) == 1, \"flow_conservation_constr2_%d\"%pr)\n",
    "\n",
    "        for pr in self.lp_pairs:\n",
    "            for n in self.lp_nodes:\n",
    "                if n not in self.pair_idx_to_sd[pr]:\n",
    "                    model += (lpSum([ratio[pr, e[0], e[1]] for e in self.lp_links if e[1] == n]) - lpSum([ratio[pr, e[0], e[1]] for e in self.lp_links if e[0] == n]) == 0, \"flow_conservation_constr3_%d_%d\"%(pr,n))\n",
    "\n",
    "        for e in self.lp_links:\n",
    "            ei = self.link_sd_to_idx[e]\n",
    "            model += (link_load[ei] == lpSum([demands[pr]*ratio[pr, e[0], e[1]] for pr in self.lp_pairs]), \"link_load_constr%d\"%ei)\n",
    "            model += (link_load[ei] <= self.link_capacities[ei]*r, \"congestion_ratio_constr%d\"%ei)\n",
    "\n",
    "        model += r + OBJ_EPSILON*lpSum([link_load[e] for e in self.links])\n",
    "\n",
    "        model.solve(solver=GLPK(msg=False))\n",
    "        assert LpStatus[model.status] == 'Optimal'\n",
    "\n",
    "        obj_r = r.value()\n",
    "        solution = {}\n",
    "        for k in ratio:\n",
    "            solution[k] = ratio[k].value()\n",
    "\n",
    "        return obj_r, solution\n",
    "       \n",
    "    def eval_optimal_routing_mlu(self, tm_idx, solution, eval_delay=False):\n",
    "        optimal_link_loads = np.zeros((self.num_links))\n",
    "        eval_tm = self.traffic_matrices[tm_idx]\n",
    "        for i in range(self.num_pairs):\n",
    "            s, d = self.pair_idx_to_sd[i]\n",
    "            demand = eval_tm[s][d]\n",
    "            for e in self.lp_links:\n",
    "                link_idx = self.link_sd_to_idx[e]\n",
    "                optimal_link_loads[link_idx] += demand*solution[i, e[0], e[1]]\n",
    "        \n",
    "        optimal_max_utilization = np.max(optimal_link_loads / self.link_capacities)\n",
    "        delay = 0\n",
    "        if eval_delay:\n",
    "            assert tm_idx in self.load_multiplier, (tm_idx)\n",
    "            optimal_link_loads *= self.load_multiplier[tm_idx]\n",
    "            delay = sum(optimal_link_loads / (self.link_capacities - optimal_link_loads))\n",
    "                        \n",
    "        return optimal_max_utilization, delay\n",
    "\n",
    "    def optimal_routing_mlu_critical_pairs(self, tm_idx, critical_pairs):\n",
    "        tm = self.traffic_matrices[tm_idx]\n",
    "\n",
    "        pairs = critical_pairs\n",
    "\n",
    "        demands = {}\n",
    "        background_link_loads = np.zeros((self.num_links))\n",
    "        for i in range(self.num_pairs):\n",
    "            s, d = self.pair_idx_to_sd[i]\n",
    "            #background link load\n",
    "            if i not in critical_pairs:\n",
    "                self.ecmp_next_hop_distribution(background_link_loads, tm[s][d], s, d)\n",
    "            else:\n",
    "                demands[i] = tm[s][d]\n",
    "\n",
    "        model = LpProblem(name=\"routing\")\n",
    "        \n",
    "        pair_links = [(pr, e[0], e[1]) for pr in pairs for e in self.lp_links] \n",
    "        ratio = LpVariable.dicts(name=\"ratio\", indexs=pair_links, lowBound=0, upBound=1)\n",
    "        \n",
    "        link_load = LpVariable.dicts(name=\"link_load\", indexs=self.links)\n",
    "\n",
    "        r = LpVariable(name=\"congestion_ratio\")\n",
    "\n",
    "        for pr in pairs:\n",
    "            model += (lpSum([ratio[pr, e[0], e[1]] for e in self.lp_links if e[1] == self.pair_idx_to_sd[pr][0]]) - lpSum([ratio[pr, e[0], e[1]] for e in self.lp_links if e[0] == self.pair_idx_to_sd[pr][0]]) == -1, \"flow_conservation_constr1_%d\"%pr)\n",
    "\n",
    "        for pr in pairs:\n",
    "            model += (lpSum([ratio[pr, e[0], e[1]] for e in self.lp_links if e[1] == self.pair_idx_to_sd[pr][1]]) - lpSum([ratio[pr, e[0], e[1]] for e in self.lp_links if e[0] == self.pair_idx_to_sd[pr][1]]) == 1, \"flow_conservation_constr2_%d\"%pr)\n",
    "\n",
    "        for pr in pairs:\n",
    "            for n in self.lp_nodes:\n",
    "                if n not in self.pair_idx_to_sd[pr]:\n",
    "                    model += (lpSum([ratio[pr, e[0], e[1]] for e in self.lp_links if e[1] == n]) - lpSum([ratio[pr, e[0], e[1]] for e in self.lp_links if e[0] == n]) == 0, \"flow_conservation_constr3_%d_%d\"%(pr,n))\n",
    "\n",
    "        for e in self.lp_links:\n",
    "            ei = self.link_sd_to_idx[e]\n",
    "            model += (link_load[ei] == background_link_loads[ei] + lpSum([demands[pr]*ratio[pr, e[0], e[1]] for pr in pairs]), \"link_load_constr%d\"%ei)\n",
    "            model += (link_load[ei] <= self.link_capacities[ei]*r, \"congestion_ratio_constr%d\"%ei)\n",
    "\n",
    "        model += r + OBJ_EPSILON*lpSum([link_load[ei] for ei in self.links])\n",
    "\n",
    "        model.solve(solver=GLPK(msg=False))\n",
    "        assert LpStatus[model.status] == 'Optimal'\n",
    "\n",
    "        obj_r = r.value()\n",
    "        solution = {}\n",
    "        for k in ratio:\n",
    "            solution[k] = ratio[k].value()\n",
    "\n",
    "        return obj_r, solution\n",
    "\n",
    "    def eval_critical_flow_and_ecmp(self, tm_idx, critical_pairs, solution, eval_delay=False):\n",
    "        eval_tm = self.traffic_matrices[tm_idx]\n",
    "        eval_link_loads = np.zeros((self.num_links))\n",
    "        for i in range(self.num_pairs):\n",
    "            s, d = self.pair_idx_to_sd[i]\n",
    "            if i not in critical_pairs:\n",
    "                self.ecmp_next_hop_distribution(eval_link_loads, eval_tm[s][d], s, d)\n",
    "            else:\n",
    "                demand = eval_tm[s][d]\n",
    "                for e in self.lp_links:\n",
    "                    link_idx = self.link_sd_to_idx[e]\n",
    "                    eval_link_loads[link_idx] += eval_tm[s][d]*solution[i, e[0], e[1]]\n",
    "\n",
    "        eval_max_utilization = np.max(eval_link_loads / self.link_capacities)\n",
    "        delay = 0\n",
    "        if eval_delay:\n",
    "            assert tm_idx in self.load_multiplier, (tm_idx)\n",
    "            eval_link_loads *= self.load_multiplier[tm_idx]\n",
    "            delay = sum(eval_link_loads / (self.link_capacities - eval_link_loads))\n",
    "        \n",
    "        return eval_max_utilization, delay\n",
    "\n",
    "    def optimal_routing_delay(self, tm_idx):\n",
    "        assert tm_idx in self.load_multiplier, (tm_idx)\n",
    "        tm = self.traffic_matrices[tm_idx]*self.load_multiplier[tm_idx]\n",
    "        demands = {}\n",
    "        for i in range(self.num_pairs):\n",
    "            s, d = self.pair_idx_to_sd[i]\n",
    "            demands[i] = tm[s][d]\n",
    "\n",
    "        model = LpProblem(name=\"routing\")\n",
    "     \n",
    "        ratio = LpVariable.dicts(name=\"ratio\", indexs=self.pair_links, lowBound=0, upBound=1)\n",
    "\n",
    "        link_load = LpVariable.dicts(name=\"link_load\", indexs=self.links)\n",
    "\n",
    "        f = LpVariable.dicts(name=\"link_cost\", indexs=self.links)\n",
    "\n",
    "        for pr in self.lp_pairs:\n",
    "            model += (lpSum([ratio[pr, e[0], e[1]] for e in self.lp_links if e[1] == self.pair_idx_to_sd[pr][0]]) - lpSum([ratio[pr, e[0], e[1]] for e in self.lp_links if e[0] == self.pair_idx_to_sd[pr][0]]) == -1, \"flow_conservation_constr1_%d\"%pr)\n",
    "\n",
    "        for pr in self.lp_pairs:\n",
    "            model += (lpSum([ratio[pr, e[0], e[1]] for e in self.lp_links if e[1] == self.pair_idx_to_sd[pr][1]]) - lpSum([ratio[pr, e[0], e[1]] for e in self.lp_links if e[0] == self.pair_idx_to_sd[pr][1]]) == 1, \"flow_conservation_constr2_%d\"%pr)\n",
    "\n",
    "        for pr in self.lp_pairs:\n",
    "            for n in self.lp_nodes:\n",
    "                if n not in self.pair_idx_to_sd[pr]:\n",
    "                    model += (lpSum([ratio[pr, e[0], e[1]] for e in self.lp_links if e[1] == n]) - lpSum([ratio[pr, e[0], e[1]] for e in self.lp_links if e[0] == n]) == 0, \"flow_conservation_constr3_%d_%d\"%(pr,n))\n",
    "\n",
    "        for e in self.lp_links:\n",
    "            ei = self.link_sd_to_idx[e]\n",
    "            model += (link_load[ei] == lpSum([demands[pr]*ratio[pr, e[0], e[1]] for pr in self.lp_pairs]), \"link_load_constr%d\"%ei)\n",
    "            model += (f[ei] * self.link_capacities[ei] >= link_load[ei], \"cost_constr1_%d\"%ei)\n",
    "            model += (f[ei] >= 3 * link_load[ei] / self.link_capacities[ei] - 2/3, \"cost_constr2_%d\"%ei)\n",
    "            model += (f[ei] >= 10 * link_load[ei] / self.link_capacities[ei] - 16/3, \"cost_constr3_%d\"%ei)\n",
    "            model += (f[ei] >= 70 * link_load[ei] / self.link_capacities[ei] - 178/3, \"cost_constr4_%d\"%ei)\n",
    "            model += (f[ei] >= 500 * link_load[ei] / self.link_capacities[ei] - 1468/3, \"cost_constr5_%d\"%ei)\n",
    "            model += (f[ei] >= 5000 * link_load[ei] / self.link_capacities[ei] - 16318/3, \"cost_constr6_%d\"%ei)\n",
    "       \n",
    "        model += lpSum(f[ei] for ei in self.links)\n",
    "\n",
    "        model.solve(solver=GLPK(msg=False))\n",
    "        assert LpStatus[model.status] == 'Optimal'\n",
    "\n",
    "        solution = {}\n",
    "        for k in ratio:\n",
    "            solution[k] = ratio[k].value()\n",
    "\n",
    "        return solution\n",
    "\n",
    "    def eval_optimal_routing_delay(self, tm_idx, solution):\n",
    "        optimal_link_loads = np.zeros((self.num_links))\n",
    "        assert tm_idx in self.load_multiplier, (tm_idx)\n",
    "        eval_tm = self.traffic_matrices[tm_idx]*self.load_multiplier[tm_idx]\n",
    "        for i in range(self.num_pairs):\n",
    "            s, d = self.pair_idx_to_sd[i]\n",
    "            demand = eval_tm[s][d]\n",
    "            for e in self.lp_links:\n",
    "                link_idx = self.link_sd_to_idx[e]\n",
    "                optimal_link_loads[link_idx] += demand*solution[i, e[0], e[1]]\n",
    "        \n",
    "        optimal_delay = sum(optimal_link_loads / (self.link_capacities - optimal_link_loads))\n",
    "\n",
    "        return optimal_delay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFRRL_Game(Game):\n",
    "    def __init__(self, config, env, random_seed=1000):\n",
    "        super(CFRRL_Game, self).__init__(config, env, random_seed)\n",
    "        \n",
    "        self.project_name = config.project_name\n",
    "        self.action_dim = env.num_pairs\n",
    "        self.max_moves = int(self.action_dim * (config.max_moves / 100.))\n",
    "        assert self.max_moves <= self.action_dim, (self.max_moves, self.action_dim)\n",
    "        \n",
    "        self.tm_history = 1\n",
    "        self.tm_indexes = np.arange(self.tm_history-1, self.tm_cnt)\n",
    "        self.valid_tm_cnt = len(self.tm_indexes)\n",
    "        \n",
    "        if config.method == 'pure_policy':\n",
    "            self.baseline = {}\n",
    "\n",
    "        self.generate_inputs(normalization=True)\n",
    "        self.state_dims = self.normalized_traffic_matrices.shape[1:]\n",
    "        print('Input dims :', self.state_dims)\n",
    "        print('Max moves :', self.max_moves)\n",
    "\n",
    "    def get_state(self, tm_idx):\n",
    "        idx_offset = self.tm_history - 1\n",
    "        return self.normalized_traffic_matrices[tm_idx-idx_offset]\n",
    "\n",
    "    def reward(self, tm_idx, actions):\n",
    "        mlu, _ = self.optimal_routing_mlu_critical_pairs(tm_idx, actions)\n",
    "\n",
    "        reward = 1 / mlu\n",
    "\n",
    "        return reward\n",
    "\n",
    "    def advantage(self, tm_idx, reward):\n",
    "        if tm_idx not in self.baseline:\n",
    "            return reward\n",
    "\n",
    "        total_v, cnt = self.baseline[tm_idx]\n",
    "        \n",
    "        #print(reward, (total_v/cnt))\n",
    "\n",
    "        return reward - (total_v/cnt)\n",
    "\n",
    "    def update_baseline(self, tm_idx, reward):\n",
    "        if tm_idx in self.baseline:\n",
    "            total_v, cnt = self.baseline[tm_idx]\n",
    "\n",
    "            total_v += reward\n",
    "            cnt += 1\n",
    "\n",
    "            self.baseline[tm_idx] = (total_v, cnt)\n",
    "        else:\n",
    "            self.baseline[tm_idx] = (reward, 1)\n",
    "\n",
    "    def evaluate(self, tm_idx, actions=None, ecmp=True, eval_delay=False):\n",
    "        \n",
    "        _, solution = self.optimal_routing_mlu(tm_idx)\n",
    "        optimal_mlu, optimal_mlu_delay = self.eval_optimal_routing_mlu(tm_idx, solution, eval_delay=eval_delay)\n",
    "        if ecmp:\n",
    "            ecmp_mlu, ecmp_delay = self.eval_ecmp_traffic_distribution(tm_idx, eval_delay=eval_delay)\n",
    "        \n",
    "        _, solution = self.optimal_routing_mlu_critical_pairs(tm_idx, actions)\n",
    "        mlu, delay = self.eval_critical_flow_and_ecmp(tm_idx, actions, solution, eval_delay=eval_delay)\n",
    "\n",
    "        crit_topk = self.get_critical_topK_flows(tm_idx)\n",
    "        _, solution = self.optimal_routing_mlu_critical_pairs(tm_idx, crit_topk)\n",
    "        crit_mlu, crit_delay = self.eval_critical_flow_and_ecmp(tm_idx, crit_topk, solution, eval_delay=eval_delay)\n",
    "\n",
    "        topk = self.get_topK_flows(tm_idx, self.lp_pairs)\n",
    "        _, solution = self.optimal_routing_mlu_critical_pairs(tm_idx, topk)\n",
    "        topk_mlu, topk_delay = self.eval_critical_flow_and_ecmp(tm_idx, topk, solution, eval_delay=eval_delay)\n",
    "\n",
    "\n",
    "        norm_mlu = optimal_mlu / mlu\n",
    "        line = str(tm_idx) + ', ' + str(norm_mlu) + ', ' + str(mlu) + ', ' \n",
    "        \n",
    "        norm_crit_mlu = optimal_mlu / crit_mlu\n",
    "        line += str(norm_crit_mlu) + ', ' + str(crit_mlu) + ', ' \n",
    "\n",
    "        norm_topk_mlu = optimal_mlu / topk_mlu\n",
    "        line += str(norm_topk_mlu) + ', ' + str(topk_mlu) + ', ' \n",
    "\n",
    "        if ecmp:\n",
    "            norm_ecmp_mlu = optimal_mlu / ecmp_mlu\n",
    "            line += str(norm_ecmp_mlu) + ', ' + str(ecmp_mlu) + ', '\n",
    "\n",
    "        if eval_delay:\n",
    "            solution = self.optimal_routing_delay(tm_idx)\n",
    "            optimal_delay = self.eval_optimal_routing_delay(tm_idx, solution) \n",
    "\n",
    "            line += str(optimal_delay/delay) + ', ' \n",
    "            line += str(optimal_delay/crit_delay) + ', ' \n",
    "            line += str(optimal_delay/topk_delay) + ', ' \n",
    "            line += str(optimal_delay/optimal_mlu_delay) + ', '\n",
    "            if ecmp:\n",
    "                line += str(optimal_delay/ecmp_delay) + ', '\n",
    "        \n",
    "            assert tm_idx in self.load_multiplier, (tm_idx)\n",
    "            line += str(self.load_multiplier[tm_idx]) + ', '\n",
    "\n",
    "        print(line[:-2])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
